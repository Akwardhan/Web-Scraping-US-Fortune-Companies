# Web Scraping & Data Structuring: U.S. Fortune Companies

## Overview  
This project demonstrates a simple but effective web scraping and data transformation process using Python. Real-world financial data was extracted from Wikipedia, cleaned, and structured into a CSV file that is ready for further analysis or visualization.

## Tools  
- Python  
- BeautifulSoup  
- Requests  
- pandas

## Dataset  
The dataset was scraped from Wikipedia's publicly available list of the largest U.S. companies by revenue. The table includes details such as:  
- Company names  
- Industry  
- Revenue figures  
- Number of employees  
- Headquarters location

## Objectives  
- Practice real-world web scraping using BeautifulSoup  
- Structure and clean raw HTML data into a usable format  
- Export the cleaned dataset as a CSV for future data analysis

## Output Preview  
ğŸ“ [`us_fortune_companies.csv`](./us_fortune_companies.csv) â€“ Final cleaned dataset

## Source Code  
ğŸ“„ [`scrape_us_fortune_companies.py`](./scrape_us_fortune_companies.py) â€“ Python script used for scraping and data processing

## Learnings  
- Hands-on experience with Python libraries used in data scraping  
- Improved skills in data wrangling with pandas  
- Understood common challenges in working with real-world web data

## Author  
*Anmol Kirtiwardhan*  
[LinkedIn](https://www.linkedin.com/in/akwardhan/)  
[Portfolio](https://your-portfolio.com)
